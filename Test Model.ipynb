{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a063150c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tutorial: https://www.analyticssteps.com/blogs/nltk-python-tutorial-beginners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c1197fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/phuongle/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/phuongle/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "#load library\n",
    "import requests\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk import pos_tag\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "import re\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fec04f69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I swear I thought the stork actually rang the bell until o saw the baby and got the jokeğŸ˜‚ğŸ˜‚ğŸ˜‚ cause after what Iâ€™ve seen animals can do now phewwwğŸ˜‚', 'am I the only one wondering how she did this?!', 'You gotta number for that stork, cause i want one.', 'Omg how cute is this!!! When she/he asks where I came from you have proof', 'so cuteğŸ¥°', 'This is amazing', 'You can order them on Amazon and they send it to your door along with the baby', 'My stork was lost for many years. Thankfully they found their way to my home ğŸ’•. This is just so precious ğŸ¥º', 'I KNEW THATS HOW IT HAPPENS!!!!', 'Thatâ€™s soooo cute!', 'This is so cute!!!', 'The lighting, sounds ğŸ¥º this is pure perfection!!', 'That is one of the best things I have seen on this app!! Congratulations ğŸ‰ğŸ’•', 'So creative! love it!!! Congratulations!', 'Omg HOW COOL', 'ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚do they accept returns', 'This is so adorable. Love thisğŸ’—ğŸ’—', 'That is toooooo cuteğŸ’œ', 'congrats for a New born', 'ğŸ¥°ğŸ¥°', 'That dog said to hell with your new carpet ğŸ˜‚', 'â€œThatâ€™s a new carpetâ€ the dog â€œnew you say ğŸ˜â€œ', 'the Chihuahua stress level with those kittens pulling up', 'the first one ğŸ’€', 'The 2 cats when the dog ranğŸ˜‚ğŸ˜‚ğŸ¤£', 'all the dogs understood all the assignments', 'the dog and the carpet omg ğŸ˜‚', 'bruh not the new carpeetğŸ’€ğŸ’€ğŸ’€', 'The last one!', 'he sed:fluff your new carpet', 'That chihuahua was scared of them kittensğŸ˜‚', 'long lives THE KING', '@orksococosoe THE NEW CARPET MADE ME GIGGLE', '@mikufan_39 omg', 'The \"Mario Dies\" theme at the end ğŸ¤£ğŸ¤£ğŸ¤£', 'ğŸ¥°ğŸ˜‚', 'ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚', 'THE KITTENS ARE SO CUTEEEEE', '@thehybridyt ğŸ’€', 'ğŸ˜‚ğŸ¥°ğŸ˜‚ğŸ¥°', 'so cute ğŸ˜‚ğŸ˜‚ğŸ˜‚', 'so sweet', 'it\\'s the middle goat\\'s \"meeee\"ğŸ˜…ğŸ˜…ğŸ˜…', 'Omg so cute!', 'The 2nd one cracked me up ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚', 'I need to start a tiny goat family of my ownğŸ¥º', 'YOU ALL HAVE A WHOLE SYMPHONY. LOVE THE SOLO BABY AT THE END..', 'First one all I could hear is Toy Story... \"The CLAWWWWW\" ğŸ˜‚', 'Whew! I feel better now ğŸ˜Š', 'Why, of the hundreds of tiktok I saw tonight, this one make me to laugh to tears? ğŸ˜‚', 'Nowadays animals really clever ğŸ˜‚ğŸ˜‚ğŸ˜‚', 'Choir present best song -nothing better then singing with your bodiesğŸ˜‚', 'Just too adorable ğŸ¥° ğŸ¥°', 'Omg so cute', 'Thatâ€™s how Iâ€™m feeling tooâ€¦mehhh!', \"ğŸ˜‚ğŸ˜‚ğŸ˜‚make my day watching this oh my G don't kill them\", 'In America, its Baaaa! ğŸ˜³', \"They're so cuteeee ğŸ˜­\", \"That's it I need a farm\", 'Iâ€™m gonna watch this every day, just because itâ€™s the best thing Iâ€™ve ever seen and it makes me smileğŸ¥°', 'I miss when my cats were kittens', 'I wish cats could stay kittens forever', '4 years and 20 pounds later, mine still has no person space', 'I miss that. the softness, the weight. the paw on my face and listening breathe. now. they do curl next to me at night. Cats are the best.', 'The love of a cat makes life worthwhile.', 'Omg I cant take the cuteness overload ğŸ˜ğŸ˜U0001faf6â¤ï¸â¤ï¸', 'Yeah theyâ€™re like that when they were little mine is not doing this in a year I miss thatğŸ¥º', 'heâ€™s so real for this', 'my kitty does the same ...she has to be close to me at all times...i am her personal property', 'When my cat was a kitten she would always sleep on my neck and this one night I woke up to her sprawled all over my neckğŸ˜­', 'I miss when my cat was a kitten now she doesnâ€™t even want to sit near me ğŸ˜­', 'i need a cat', 'the tail mustache ğŸ¥°', 'This is why i want a cat', 'miss when my cats were babies and would actually cuddle w me :(', 'i miss this..', 'I WANT IT', 'i miss when my cat did this man', 'This is so cute', 'Thatâ€™s a baby cat', 'ğŸ˜€', 'ğŸ¤£ğŸ˜‚ğŸ¤£ğŸ˜‚', 'ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚', 'ğŸ˜‚ğŸ˜‚ğŸ˜‚', 'ğŸ˜‚ğŸ˜‚ğŸ˜‚', 'ğŸ¥°ğŸ˜‚', 'ğŸ˜‚ğŸ˜‚ğŸ˜‚', 'ğŸ˜…ğŸ˜‚ğŸ˜‚ğŸ˜‚', 'ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚', 'ğŸ˜‚ğŸ˜‚ğŸ˜‚', 'ğŸ˜‚ğŸ˜‚ğŸ˜‚', 'ğŸ˜', 'ğŸ˜‚ğŸ˜‚', 'ğŸ˜‚', 'ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚', 'ğŸ˜‚ğŸ˜‚', 'ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚', 'ğŸ˜‚', 'ğŸ˜‚ğŸ˜‚ğŸ˜‚', 'pov you older siblings asking for a sip', \"ok ok it's all urs\", 'Polite burp', 'I canâ€™t Iâ€™d hiccup straight away ğŸ˜‚ğŸ˜‚', 'How can she do that', '\"can I have a sip?\"', \"don't really get it?\", '@ã„’å°ºä¸¨ä¹‚ me when I say can i have a sip of your drink', 'I would be crying U0001f979', '@explodingburgerzz me when im home alone', 'Me with Diet Coke', '@caseyteaxx me with cola ğŸ˜‚', 'Defo hungover', '@JU0001faac you', 'me in the gym on the treadmill ğŸ˜‚', 'fr me with Radnor fizz', '@U0001fae7 so you', 'I drank a bottle like this once and I threw up loads after', \"@heisenberg_gn and it's cold...I feel pain\", '@tessieâ™¡ the burps are so couqette', 'I refuse to believe she uses even half of that', 'sephora dupe', 'so satisfying but so much wasteğŸ˜¢', 'half of these products are never going to get touched again', 'it just kept going', 'i think she likes makeup guys', \"It's giving drumline :)\", 'and my mom tells me i own too much makeupğŸ’€', 'Me in 5 years', 'if only I had the money ğŸ’”', 'I donâ€™t have that much', 'ILL TAKE a COUPLE ğŸ¥ğŸ˜­', 'How is this even sustainable? Environmentally & use wiseğŸ˜ª', 'same', 'Shawty buy every product of each brand', 'How many of those you think are expired?', 'someone tell me why i watched this whole thing', 'i aspire to be like this', 'Imagine how expensive all this is', 'Thatâ€™s my favorite hole life savings lol', 'Best story ever! I need a part 2 from baby!', 'i love baby babble so much', 'baby fever, Baby Fever, BABY FEVER!!!', 'the wrist roll ğŸ˜­ğŸ˜­ğŸ˜­ so cute', 'babies listening to their own voices is just so cute!', \"It's funny to think about how babies probably don't know when they say their first word because they probably think they're talking all the time.\", 'Omg her covering her mouth while yawningâ€¦ ugh adorable â˜ºï¸', 'That was the most in depth story ever! I was hooked', \"that's how her day wentğŸ˜‚ğŸ˜‚\", 'the covering her mouth for the yawn ğŸ¥ºâ¤ï¸', 'i love baby voices ğŸ¥ºğŸ¥º', 'oh my goodness she is so precious U0001f979', 'The caption U0001f979U0001f979', 'ğŸ¥±ğŸ¥±ğŸ¥±oh my goodnessğŸ¥°ğŸ¥°ğŸ¥°', \"it's like she's telling a very serious story about dada!ğŸ˜‚ğŸ˜‚ğŸ¥°ğŸ¥°ğŸ¥°\", 'I donâ€™t want another baby i donâ€™t want another baby i donâ€™t want another baby ğŸ˜‚ğŸ˜‚ğŸ˜©ğŸ˜©ğŸ˜©ğŸ˜©', 'her covering her yawn ğŸ¥º', 'OMG . So cute ğŸ¥°ğŸ¥°', 'She is so adorable!!', 'Oh no she covered her mouth yawning!!!! That is so cute']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "159"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load json data from github \n",
    "# import urllib library\n",
    "from urllib.request import urlopen\n",
    "  \n",
    "# import json\n",
    "import json\n",
    "# store the URL in url as \n",
    "# parameter for urlopen\n",
    "url = \"https://raw.githubusercontent.com/bachdumpling/genz-dictionary-model/main/comments.json\"\n",
    "  \n",
    "# store the response of URL\n",
    "response = urlopen(url)\n",
    "  \n",
    "# storing the JSON response \n",
    "# from url in data\n",
    "dataset = json.loads(response.read())\n",
    "  \n",
    "# print the json response\n",
    "print(dataset)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "274686c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['I', 'swear', 'I', 'thought', 'the', 'stork', 'actually', 'rang', 'the', 'bell', 'until', 'o', 'saw', 'the', 'baby', 'and', 'got', 'the', 'jokeğŸ˜‚ğŸ˜‚ğŸ˜‚', 'cause', 'after', 'what', 'I', 'â€™', 've', 'seen', 'animals', 'can', 'do', 'now', 'phewwwğŸ˜‚'], ['am', 'I', 'the', 'only', 'one', 'wondering', 'how', 'she', 'did', 'this', '?', '!'], ['You', 'got', 'ta', 'number', 'for', 'that', 'stork', ',', 'cause', 'i', 'want', 'one', '.'], ['Omg', 'how', 'cute', 'is', 'this', '!', '!', '!', 'When', 'she/he', 'asks', 'where', 'I', 'came', 'from', 'you', 'have', 'proof'], ['so', 'cuteğŸ¥°'], ['This', 'is', 'amazing'], ['You', 'can', 'order', 'them', 'on', 'Amazon', 'and', 'they', 'send', 'it', 'to', 'your', 'door', 'along', 'with', 'the', 'baby'], ['My', 'stork', 'was', 'lost', 'for', 'many', 'years', '.', 'Thankfully', 'they', 'found', 'their', 'way', 'to', 'my', 'home', 'ğŸ’•', '.', 'This', 'is', 'just', 'so', 'precious', 'ğŸ¥º'], ['I', 'KNEW', 'THATS', 'HOW', 'IT', 'HAPPENS', '!', '!', '!', '!'], ['That', 'â€™', 's', 'soooo', 'cute', '!'], ['This', 'is', 'so', 'cute', '!', '!', '!'], ['The', 'lighting', ',', 'sounds', 'ğŸ¥º', 'this', 'is', 'pure', 'perfection', '!', '!'], ['That', 'is', 'one', 'of', 'the', 'best', 'things', 'I', 'have', 'seen', 'on', 'this', 'app', '!', '!', 'Congratulations', 'ğŸ‰ğŸ’•'], ['So', 'creative', '!', 'love', 'it', '!', '!', '!', 'Congratulations', '!'], ['Omg', 'HOW', 'COOL'], ['ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚do', 'they', 'accept', 'returns'], ['This', 'is', 'so', 'adorable', '.', 'Love', 'thisğŸ’—ğŸ’—'], ['That', 'is', 'toooooo', 'cuteğŸ’œ'], ['congrats', 'for', 'a', 'New', 'born'], ['ğŸ¥°ğŸ¥°'], ['That', 'dog', 'said', 'to', 'hell', 'with', 'your', 'new', 'carpet', 'ğŸ˜‚'], ['â€œ', 'That', 'â€™', 's', 'a', 'new', 'carpet', 'â€', 'the', 'dog', 'â€œ', 'new', 'you', 'say', 'ğŸ˜', 'â€œ'], ['the', 'Chihuahua', 'stress', 'level', 'with', 'those', 'kittens', 'pulling', 'up'], ['the', 'first', 'one', 'ğŸ’€'], ['The', '2', 'cats', 'when', 'the', 'dog', 'ranğŸ˜‚ğŸ˜‚ğŸ¤£'], ['all', 'the', 'dogs', 'understood', 'all', 'the', 'assignments'], ['the', 'dog', 'and', 'the', 'carpet', 'omg', 'ğŸ˜‚'], ['bruh', 'not', 'the', 'new', 'carpeetğŸ’€ğŸ’€ğŸ’€'], ['The', 'last', 'one', '!'], ['he', 'sed', ':', 'fluff', 'your', 'new', 'carpet'], ['That', 'chihuahua', 'was', 'scared', 'of', 'them', 'kittensğŸ˜‚'], ['long', 'lives', 'THE', 'KING'], ['@', 'orksococosoe', 'THE', 'NEW', 'CARPET', 'MADE', 'ME', 'GIGGLE'], ['@', 'mikufan_39', 'omg'], ['The', '``', 'Mario', 'Dies', \"''\", 'theme', 'at', 'the', 'end', 'ğŸ¤£ğŸ¤£ğŸ¤£'], ['ğŸ¥°ğŸ˜‚'], ['ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚'], ['THE', 'KITTENS', 'ARE', 'SO', 'CUTEEEEE'], ['@', 'thehybridyt', 'ğŸ’€'], ['ğŸ˜‚ğŸ¥°ğŸ˜‚ğŸ¥°'], ['so', 'cute', 'ğŸ˜‚ğŸ˜‚ğŸ˜‚'], ['so', 'sweet'], ['it', \"'s\", 'the', 'middle', 'goat', \"'s\", '``', 'meeee', \"''\", 'ğŸ˜…ğŸ˜…ğŸ˜…'], ['Omg', 'so', 'cute', '!'], ['The', '2nd', 'one', 'cracked', 'me', 'up', 'ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚'], ['I', 'need', 'to', 'start', 'a', 'tiny', 'goat', 'family', 'of', 'my', 'ownğŸ¥º'], ['YOU', 'ALL', 'HAVE', 'A', 'WHOLE', 'SYMPHONY', '.', 'LOVE', 'THE', 'SOLO', 'BABY', 'AT', 'THE', 'END', '..'], ['First', 'one', 'all', 'I', 'could', 'hear', 'is', 'Toy', 'Story', '...', '``', 'The', 'CLAWWWWW', \"''\", 'ğŸ˜‚'], ['Whew', '!', 'I', 'feel', 'better', 'now', 'ğŸ˜Š'], ['Why', ',', 'of', 'the', 'hundreds', 'of', 'tiktok', 'I', 'saw', 'tonight', ',', 'this', 'one', 'make', 'me', 'to', 'laugh', 'to', 'tears', '?', 'ğŸ˜‚'], ['Nowadays', 'animals', 'really', 'clever', 'ğŸ˜‚ğŸ˜‚ğŸ˜‚'], ['Choir', 'present', 'best', 'song', '-nothing', 'better', 'then', 'singing', 'with', 'your', 'bodiesğŸ˜‚'], ['Just', 'too', 'adorable', 'ğŸ¥°', 'ğŸ¥°'], ['Omg', 'so', 'cute'], ['That', 'â€™', 's', 'how', 'I', 'â€™', 'm', 'feeling', 'tooâ€¦mehhh', '!'], ['ğŸ˜‚ğŸ˜‚ğŸ˜‚make', 'my', 'day', 'watching', 'this', 'oh', 'my', 'G', 'do', \"n't\", 'kill', 'them'], ['In', 'America', ',', 'its', 'Baaaa', '!', 'ğŸ˜³'], ['They', \"'re\", 'so', 'cuteeee', 'ğŸ˜­'], ['That', \"'s\", 'it', 'I', 'need', 'a', 'farm'], ['I', 'â€™', 'm', 'gon', 'na', 'watch', 'this', 'every', 'day', ',', 'just', 'because', 'it', 'â€™', 's', 'the', 'best', 'thing', 'I', 'â€™', 've', 'ever', 'seen', 'and', 'it', 'makes', 'me', 'smileğŸ¥°'], ['I', 'miss', 'when', 'my', 'cats', 'were', 'kittens'], ['I', 'wish', 'cats', 'could', 'stay', 'kittens', 'forever'], ['4', 'years', 'and', '20', 'pounds', 'later', ',', 'mine', 'still', 'has', 'no', 'person', 'space'], ['I', 'miss', 'that', '.', 'the', 'softness', ',', 'the', 'weight', '.', 'the', 'paw', 'on', 'my', 'face', 'and', 'listening', 'breathe', '.', 'now', '.', 'they', 'do', 'curl', 'next', 'to', 'me', 'at', 'night', '.', 'Cats', 'are', 'the', 'best', '.'], ['The', 'love', 'of', 'a', 'cat', 'makes', 'life', 'worthwhile', '.'], ['Omg', 'I', 'cant', 'take', 'the', 'cuteness', 'overload', 'ğŸ˜ğŸ˜U0001faf6â¤ï¸â¤ï¸'], ['Yeah', 'they', 'â€™', 're', 'like', 'that', 'when', 'they', 'were', 'little', 'mine', 'is', 'not', 'doing', 'this', 'in', 'a', 'year', 'I', 'miss', 'thatğŸ¥º'], ['he', 'â€™', 's', 'so', 'real', 'for', 'this'], ['my', 'kitty', 'does', 'the', 'same', '...', 'she', 'has', 'to', 'be', 'close', 'to', 'me', 'at', 'all', 'times', '...', 'i', 'am', 'her', 'personal', 'property'], ['When', 'my', 'cat', 'was', 'a', 'kitten', 'she', 'would', 'always', 'sleep', 'on', 'my', 'neck', 'and', 'this', 'one', 'night', 'I', 'woke', 'up', 'to', 'her', 'sprawled', 'all', 'over', 'my', 'neckğŸ˜­'], ['I', 'miss', 'when', 'my', 'cat', 'was', 'a', 'kitten', 'now', 'she', 'doesn', 'â€™', 't', 'even', 'want', 'to', 'sit', 'near', 'me', 'ğŸ˜­'], ['i', 'need', 'a', 'cat'], ['the', 'tail', 'mustache', 'ğŸ¥°'], ['This', 'is', 'why', 'i', 'want', 'a', 'cat'], ['miss', 'when', 'my', 'cats', 'were', 'babies', 'and', 'would', 'actually', 'cuddle', 'w', 'me', ':', '('], ['i', 'miss', 'this', '..'], ['I', 'WANT', 'IT'], ['i', 'miss', 'when', 'my', 'cat', 'did', 'this', 'man'], ['This', 'is', 'so', 'cute'], ['That', 'â€™', 's', 'a', 'baby', 'cat'], ['ğŸ˜€'], ['ğŸ¤£ğŸ˜‚ğŸ¤£ğŸ˜‚'], ['ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚'], ['ğŸ˜‚ğŸ˜‚ğŸ˜‚'], ['ğŸ˜‚ğŸ˜‚ğŸ˜‚'], ['ğŸ¥°ğŸ˜‚'], ['ğŸ˜‚ğŸ˜‚ğŸ˜‚'], ['ğŸ˜…ğŸ˜‚ğŸ˜‚ğŸ˜‚'], ['ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚'], ['ğŸ˜‚ğŸ˜‚ğŸ˜‚'], ['ğŸ˜‚ğŸ˜‚ğŸ˜‚'], ['ğŸ˜'], ['ğŸ˜‚ğŸ˜‚'], ['ğŸ˜‚'], ['ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚'], ['ğŸ˜‚ğŸ˜‚'], ['ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚'], ['ğŸ˜‚'], ['ğŸ˜‚ğŸ˜‚ğŸ˜‚'], ['pov', 'you', 'older', 'siblings', 'asking', 'for', 'a', 'sip'], ['ok', 'ok', 'it', \"'s\", 'all', 'urs'], ['Polite', 'burp'], ['I', 'can', 'â€™', 't', 'I', 'â€™', 'd', 'hiccup', 'straight', 'away', 'ğŸ˜‚ğŸ˜‚'], ['How', 'can', 'she', 'do', 'that'], ['``', 'can', 'I', 'have', 'a', 'sip', '?', \"''\"], ['do', \"n't\", 'really', 'get', 'it', '?'], ['@', 'ã„’å°ºä¸¨ä¹‚', 'me', 'when', 'I', 'say', 'can', 'i', 'have', 'a', 'sip', 'of', 'your', 'drink'], ['I', 'would', 'be', 'crying', 'U0001f979'], ['@', 'explodingburgerzz', 'me', 'when', 'im', 'home', 'alone'], ['Me', 'with', 'Diet', 'Coke'], ['@', 'caseyteaxx', 'me', 'with', 'cola', 'ğŸ˜‚'], ['Defo', 'hungover'], ['@', 'JU0001faac', 'you'], ['me', 'in', 'the', 'gym', 'on', 'the', 'treadmill', 'ğŸ˜‚'], ['fr', 'me', 'with', 'Radnor', 'fizz'], ['@', 'U0001fae7', 'so', 'you'], ['I', 'drank', 'a', 'bottle', 'like', 'this', 'once', 'and', 'I', 'threw', 'up', 'loads', 'after'], ['@', 'heisenberg_gn', 'and', 'it', \"'s\", 'cold', '...', 'I', 'feel', 'pain'], ['@', 'tessieâ™¡', 'the', 'burps', 'are', 'so', 'couqette'], ['I', 'refuse', 'to', 'believe', 'she', 'uses', 'even', 'half', 'of', 'that'], ['sephora', 'dupe'], ['so', 'satisfying', 'but', 'so', 'much', 'wasteğŸ˜¢'], ['half', 'of', 'these', 'products', 'are', 'never', 'going', 'to', 'get', 'touched', 'again'], ['it', 'just', 'kept', 'going'], ['i', 'think', 'she', 'likes', 'makeup', 'guys'], ['It', \"'s\", 'giving', 'drumline', ':', ')'], ['and', 'my', 'mom', 'tells', 'me', 'i', 'own', 'too', 'much', 'makeupğŸ’€'], ['Me', 'in', '5', 'years'], ['if', 'only', 'I', 'had', 'the', 'money', 'ğŸ’”'], ['I', 'don', 'â€™', 't', 'have', 'that', 'much'], ['ILL', 'TAKE', 'a', 'COUPLE', 'ğŸ¥ğŸ˜­'], ['How', 'is', 'this', 'even', 'sustainable', '?', 'Environmentally', '&', 'use', 'wiseğŸ˜ª'], ['same'], ['Shawty', 'buy', 'every', 'product', 'of', 'each', 'brand'], ['How', 'many', 'of', 'those', 'you', 'think', 'are', 'expired', '?'], ['someone', 'tell', 'me', 'why', 'i', 'watched', 'this', 'whole', 'thing'], ['i', 'aspire', 'to', 'be', 'like', 'this'], ['Imagine', 'how', 'expensive', 'all', 'this', 'is'], ['That', 'â€™', 's', 'my', 'favorite', 'hole', 'life', 'savings', 'lol'], ['Best', 'story', 'ever', '!', 'I', 'need', 'a', 'part', '2', 'from', 'baby', '!'], ['i', 'love', 'baby', 'babble', 'so', 'much'], ['baby', 'fever', ',', 'Baby', 'Fever', ',', 'BABY', 'FEVER', '!', '!', '!'], ['the', 'wrist', 'roll', 'ğŸ˜­ğŸ˜­ğŸ˜­', 'so', 'cute'], ['babies', 'listening', 'to', 'their', 'own', 'voices', 'is', 'just', 'so', 'cute', '!'], ['It', \"'s\", 'funny', 'to', 'think', 'about', 'how', 'babies', 'probably', 'do', \"n't\", 'know', 'when', 'they', 'say', 'their', 'first', 'word', 'because', 'they', 'probably', 'think', 'they', \"'re\", 'talking', 'all', 'the', 'time', '.'], ['Omg', 'her', 'covering', 'her', 'mouth', 'while', 'yawningâ€¦', 'ugh', 'adorable', 'â˜ºï¸'], ['That', 'was', 'the', 'most', 'in', 'depth', 'story', 'ever', '!', 'I', 'was', 'hooked'], ['that', \"'s\", 'how', 'her', 'day', 'wentğŸ˜‚ğŸ˜‚'], ['the', 'covering', 'her', 'mouth', 'for', 'the', 'yawn', 'ğŸ¥ºâ¤ï¸'], ['i', 'love', 'baby', 'voices', 'ğŸ¥ºğŸ¥º'], ['oh', 'my', 'goodness', 'she', 'is', 'so', 'precious', 'U0001f979'], ['The', 'caption', 'U0001f979U0001f979'], ['ğŸ¥±ğŸ¥±ğŸ¥±oh', 'my', 'goodnessğŸ¥°ğŸ¥°ğŸ¥°'], ['it', \"'s\", 'like', 'she', \"'s\", 'telling', 'a', 'very', 'serious', 'story', 'about', 'dada', '!', 'ğŸ˜‚ğŸ˜‚ğŸ¥°ğŸ¥°ğŸ¥°'], ['I', 'don', 'â€™', 't', 'want', 'another', 'baby', 'i', 'don', 'â€™', 't', 'want', 'another', 'baby', 'i', 'don', 'â€™', 't', 'want', 'another', 'baby', 'ğŸ˜‚ğŸ˜‚ğŸ˜©ğŸ˜©ğŸ˜©ğŸ˜©'], ['her', 'covering', 'her', 'yawn', 'ğŸ¥º'], ['OMG', '.', 'So', 'cute', 'ğŸ¥°ğŸ¥°'], ['She', 'is', 'so', 'adorable', '!', '!'], ['Oh', 'no', 'she', 'covered', 'her', 'mouth', 'yawning', '!', '!', '!', '!', 'That', 'is', 'so', 'cute']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "159"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data Cleaning \n",
    "accepted_sentence = []\n",
    "\n",
    "#Word Tokenization\n",
    "for sentence in dataset: \n",
    "    tokenized = word_tokenize(sentence)\n",
    "    accepted_sentence.append(tokenized)\n",
    "    \n",
    "print(accepted_sentence)\n",
    "len(accepted_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39de7a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/phuongle/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "#Remove Punctuation\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    " \n",
    "\n",
    "from string import punctuation\n",
    "\n",
    "punctuation = list(punctuation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fe356072",
   "metadata": {},
   "outputs": [],
   "source": [
    "functionWords = [\n",
    "    \"I\", \"a\",\n",
    "    \"an\",\n",
    "    \"the\",\n",
    "    \"and\",\n",
    "    \"but\",\n",
    "    \"or\",\n",
    "    \"as\",\n",
    "    \"if\",\n",
    "    \"when\",\n",
    "    \"than\",\n",
    "    \"because\",\n",
    "    \"though\",\n",
    "    \"although\",\n",
    "    \"while\",\n",
    "    \"where\",\n",
    "    \"after\",\n",
    "    \"before\",\n",
    "    \"since\",\n",
    "    \"until\",\n",
    "    \"by\",\n",
    "    \"with\",\n",
    "    \"without\",\n",
    "    \"under\",\n",
    "    \"over\",\n",
    "    \"in\",\n",
    "    \"on\",\n",
    "    \"at\",\n",
    "    \"to\",\n",
    "    \"from\",\n",
    "    \"into\",\n",
    "    \"onto\",\n",
    "    \"out\",\n",
    "    \"off\",\n",
    "    \"up\",\n",
    "    \"down\",\n",
    "    \"through\",\n",
    "    \"around\",\n",
    "    \"about\",\n",
    "    \"above\",\n",
    "    \"below\",\n",
    "    \"near\",\n",
    "    \"far\",\n",
    "    \"along\",\n",
    "    \"across\",\n",
    "    \"behind\",\n",
    "    \"beside\",\n",
    "    \"between\",\n",
    "    \"beyond\",\n",
    "    \"inside\",\n",
    "    \"outside\",\n",
    "    \"throughout\",\n",
    "    \"toward\",\n",
    "    \"towards\",\n",
    "    \"via\",\n",
    "    \"among\",\n",
    "    \"amongst\",\n",
    "    \"within\",\n",
    "    \"without\",\n",
    "    \"ago\",\n",
    "    \"now\",\n",
    "    \"just\",\n",
    "    \"already\",\n",
    "    \"still\",\n",
    "    \"even\",\n",
    "    \"only\",\n",
    "    \"almost\",\n",
    "    \"nearly\",\n",
    "    \"perhaps\",\n",
    "    \"maybe\",\n",
    "    \"certainly\",\n",
    "    \"surely\",\n",
    "    \"really\",\n",
    "    \"truly\",\n",
    "    \"sincerely\",\n",
    "    \"actually\",\n",
    "    \"definitely\",\n",
    "    \"practically\",\n",
    "    \"ultimately\",\n",
    "    \"basically\",\n",
    "    \"generally\",\n",
    "    \"mostly\",\n",
    "    \"often\",\n",
    "    \"sometimes\",\n",
    "    \"rarely\",\n",
    "    \"seldom\",\n",
    "    \"never\",\n",
    "    \"ever\",\n",
    "    \"always\",\n",
    "    \"together\",\n",
    "    \"apart\",\n",
    "    \"thus\",\n",
    "    \"therefore\",\n",
    "    \"hence\",\n",
    "    \"so\",\n",
    "    \"then\",\n",
    "    \"nowadays\",\n",
    "    \"meanwhile\",\n",
    "    \"forthwith\",\n",
    "    \"later\",\n",
    "    \"sooner\",\n",
    "    \"instead\",\n",
    "    \"nevertheless\",\n",
    "    \"however\",\n",
    "    \"furthermore\",\n",
    "    \"moreover\",\n",
    "    \"in addition\",\n",
    "    \"in contrast\",\n",
    "    \"in fact\",\n",
    "    \"indeed\",\n",
    "    \"that\",\n",
    "    \"what\",\n",
    "    \"which\",\n",
    "    \"who\",\n",
    "    \"whom\",\n",
    "    \"whose\",\n",
    "    \"where\",\n",
    "    \"when\",\n",
    "    \"why\",\n",
    "    \"how\",\n",
    "    \"thats\",\n",
    "    '\"',\n",
    "    \" \",\n",
    "    'â€™'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5dd96e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_tokens = word_tokenize(dataset[0])\n",
    "len(tokens)\n",
    "tokens = list(set(duplicated_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6c38256c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['actually',\n",
       " 'I',\n",
       " 'seen',\n",
       " 'the',\n",
       " 'bell',\n",
       " 'got',\n",
       " 'o',\n",
       " 'can',\n",
       " 'rang',\n",
       " 'stork',\n",
       " 'saw',\n",
       " 've',\n",
       " 'jokeğŸ˜‚ğŸ˜‚ğŸ˜‚',\n",
       " 'animals',\n",
       " 'phewwwğŸ˜‚',\n",
       " 'now',\n",
       " 'â€™',\n",
       " 'baby',\n",
       " 'after',\n",
       " 'and',\n",
       " 'thought',\n",
       " 'until',\n",
       " 'swear',\n",
       " 'do',\n",
       " 'cause',\n",
       " 'what']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5c999185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['seen', 'bell', 'got', 'rang', 'stork', 'saw', 'jokeğŸ˜‚ğŸ˜‚ğŸ˜‚', 'animals', 'phewwwğŸ˜‚', 'baby', 'thought', 'swear', 'cause']\n"
     ]
    }
   ],
   "source": [
    "accepted_list = []\n",
    "# cleaned_tokens = [token for token in tokens if token not in stopwords or token not in functionWords and token not in punctuation]  \n",
    "cleaned_tokens = [token.lower() for token in tokens if token.lower() not in stopwords and token.lower() not in functionWords and token.lower() not in punctuation]\n",
    "accepted_list.append(cleaned_tokens)\n",
    "print(cleaned_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8f84abbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['seen', 'seen bell', 'seen bell got', 'seen bell got rang', 'seen bell got rang stork', 'seen bell got rang stork saw', 'seen bell got rang stork saw jokeğŸ˜‚ğŸ˜‚ğŸ˜‚', 'seen bell got rang stork saw jokeğŸ˜‚ğŸ˜‚ğŸ˜‚ animals', 'seen bell got rang stork saw jokeğŸ˜‚ğŸ˜‚ğŸ˜‚ animals phewwwğŸ˜‚', 'seen bell got rang stork saw jokeğŸ˜‚ğŸ˜‚ğŸ˜‚ animals phewwwğŸ˜‚ baby', 'seen bell got rang stork saw jokeğŸ˜‚ğŸ˜‚ğŸ˜‚ animals phewwwğŸ˜‚ baby thought', 'seen bell got rang stork saw jokeğŸ˜‚ğŸ˜‚ğŸ˜‚ animals phewwwğŸ˜‚ baby thought swear', 'seen bell got rang stork saw jokeğŸ˜‚ğŸ˜‚ğŸ˜‚ animals phewwwğŸ˜‚ baby thought swear cause', 'bell', 'bell got', 'bell got rang', 'bell got rang stork', 'bell got rang stork saw', 'bell got rang stork saw jokeğŸ˜‚ğŸ˜‚ğŸ˜‚', 'bell got rang stork saw jokeğŸ˜‚ğŸ˜‚ğŸ˜‚ animals', 'bell got rang stork saw jokeğŸ˜‚ğŸ˜‚ğŸ˜‚ animals phewwwğŸ˜‚', 'bell got rang stork saw jokeğŸ˜‚ğŸ˜‚ğŸ˜‚ animals phewwwğŸ˜‚ baby', 'bell got rang stork saw jokeğŸ˜‚ğŸ˜‚ğŸ˜‚ animals phewwwğŸ˜‚ baby thought', 'bell got rang stork saw jokeğŸ˜‚ğŸ˜‚ğŸ˜‚ animals phewwwğŸ˜‚ baby thought swear', 'bell got rang stork saw jokeğŸ˜‚ğŸ˜‚ğŸ˜‚ animals phewwwğŸ˜‚ baby thought swear cause', 'got', 'got rang', 'got rang stork', 'got rang stork saw', 'got rang stork saw jokeğŸ˜‚ğŸ˜‚ğŸ˜‚', 'got rang stork saw jokeğŸ˜‚ğŸ˜‚ğŸ˜‚ animals', 'got rang stork saw jokeğŸ˜‚ğŸ˜‚ğŸ˜‚ animals phewwwğŸ˜‚', 'got rang stork saw jokeğŸ˜‚ğŸ˜‚ğŸ˜‚ animals phewwwğŸ˜‚ baby', 'got rang stork saw jokeğŸ˜‚ğŸ˜‚ğŸ˜‚ animals phewwwğŸ˜‚ baby thought', 'got rang stork saw jokeğŸ˜‚ğŸ˜‚ğŸ˜‚ animals phewwwğŸ˜‚ baby thought swear', 'got rang stork saw jokeğŸ˜‚ğŸ˜‚ğŸ˜‚ animals phewwwğŸ˜‚ baby thought swear cause', 'rang', 'rang stork', 'rang stork saw', 'rang stork saw jokeğŸ˜‚ğŸ˜‚ğŸ˜‚', 'rang stork saw jokeğŸ˜‚ğŸ˜‚ğŸ˜‚ animals', 'rang stork saw jokeğŸ˜‚ğŸ˜‚ğŸ˜‚ animals phewwwğŸ˜‚', 'rang stork saw jokeğŸ˜‚ğŸ˜‚ğŸ˜‚ animals phewwwğŸ˜‚ baby', 'rang stork saw jokeğŸ˜‚ğŸ˜‚ğŸ˜‚ animals phewwwğŸ˜‚ baby thought', 'rang stork saw jokeğŸ˜‚ğŸ˜‚ğŸ˜‚ animals phewwwğŸ˜‚ baby thought swear', 'rang stork saw jokeğŸ˜‚ğŸ˜‚ğŸ˜‚ animals phewwwğŸ˜‚ baby thought swear cause', 'stork', 'stork saw', 'stork saw jokeğŸ˜‚ğŸ˜‚ğŸ˜‚', 'stork saw jokeğŸ˜‚ğŸ˜‚ğŸ˜‚ animals', 'stork saw jokeğŸ˜‚ğŸ˜‚ğŸ˜‚ animals phewwwğŸ˜‚', 'stork saw jokeğŸ˜‚ğŸ˜‚ğŸ˜‚ animals phewwwğŸ˜‚ baby', 'stork saw jokeğŸ˜‚ğŸ˜‚ğŸ˜‚ animals phewwwğŸ˜‚ baby thought', 'stork saw jokeğŸ˜‚ğŸ˜‚ğŸ˜‚ animals phewwwğŸ˜‚ baby thought swear', 'stork saw jokeğŸ˜‚ğŸ˜‚ğŸ˜‚ animals phewwwğŸ˜‚ baby thought swear cause', 'saw', 'saw jokeğŸ˜‚ğŸ˜‚ğŸ˜‚', 'saw jokeğŸ˜‚ğŸ˜‚ğŸ˜‚ animals', 'saw jokeğŸ˜‚ğŸ˜‚ğŸ˜‚ animals phewwwğŸ˜‚', 'saw jokeğŸ˜‚ğŸ˜‚ğŸ˜‚ animals phewwwğŸ˜‚ baby', 'saw jokeğŸ˜‚ğŸ˜‚ğŸ˜‚ animals phewwwğŸ˜‚ baby thought', 'saw jokeğŸ˜‚ğŸ˜‚ğŸ˜‚ animals phewwwğŸ˜‚ baby thought swear', 'saw jokeğŸ˜‚ğŸ˜‚ğŸ˜‚ animals phewwwğŸ˜‚ baby thought swear cause', 'jokeğŸ˜‚ğŸ˜‚ğŸ˜‚', 'jokeğŸ˜‚ğŸ˜‚ğŸ˜‚ animals', 'jokeğŸ˜‚ğŸ˜‚ğŸ˜‚ animals phewwwğŸ˜‚', 'jokeğŸ˜‚ğŸ˜‚ğŸ˜‚ animals phewwwğŸ˜‚ baby', 'jokeğŸ˜‚ğŸ˜‚ğŸ˜‚ animals phewwwğŸ˜‚ baby thought', 'jokeğŸ˜‚ğŸ˜‚ğŸ˜‚ animals phewwwğŸ˜‚ baby thought swear', 'jokeğŸ˜‚ğŸ˜‚ğŸ˜‚ animals phewwwğŸ˜‚ baby thought swear cause', 'animals', 'animals phewwwğŸ˜‚', 'animals phewwwğŸ˜‚ baby', 'animals phewwwğŸ˜‚ baby thought', 'animals phewwwğŸ˜‚ baby thought swear', 'animals phewwwğŸ˜‚ baby thought swear cause', 'phewwwğŸ˜‚', 'phewwwğŸ˜‚ baby', 'phewwwğŸ˜‚ baby thought', 'phewwwğŸ˜‚ baby thought swear', 'phewwwğŸ˜‚ baby thought swear cause', 'baby', 'baby thought', 'baby thought swear', 'baby thought swear cause', 'thought', 'thought swear', 'thought swear cause', 'swear', 'swear cause', 'cause']\n"
     ]
    }
   ],
   "source": [
    "# generate a list of all possible combinations of words in order\n",
    "combinations = []\n",
    "for i in range(len(cleaned_tokens)):\n",
    "    for j in range(i+1, len(cleaned_tokens)+1):\n",
    "        combinations.append(\" \".join(cleaned_tokens[i:j]))\n",
    "\n",
    "print(combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "84efab63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['seen', 'seen bell', 'seen bell got', 'seen bell got rang', 'seen bell got rang stork', 'seen bell got rang stork saw', 'seen bell got rang stork saw jokeğŸ˜‚ğŸ˜‚ğŸ˜‚', 'seen bell got rang stork saw jokeğŸ˜‚ğŸ˜‚ğŸ˜‚ animals', 'seen bell got rang stork saw jokeğŸ˜‚ğŸ˜‚ğŸ˜‚ animals phewwwğŸ˜‚']\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# calculate the frequency distribution of the words\n",
    "freq_dist = FreqDist(combinations)\n",
    "\n",
    "# determine the number of unique words in the text\n",
    "num_unique_words = len(freq_dist)\n",
    "\n",
    "# calculate the number of words to include in the top 25%\n",
    "num_top_words = int(num_unique_words * 0.1)\n",
    "\n",
    "# construct a list of the top 25% most common words\n",
    "top_words = [word for word, freq in freq_dist.most_common(num_top_words)]\n",
    "\n",
    "print(top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a4989f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'seen': 1, 'seen bell': 1, 'seen bell got': 1, 'seen bell got rang': 1, 'seen bell got rang stork': 1, 'seen bell got rang stork saw': 1, 'seen bell got rang stork saw jokeğŸ˜‚ğŸ˜‚ğŸ˜‚': 1, 'seen bell got rang stork saw jokeğŸ˜‚ğŸ˜‚ğŸ˜‚ animals': 1, 'seen bell got rang stork saw jokeğŸ˜‚ğŸ˜‚ğŸ˜‚ animals phewwwğŸ˜‚': 1, 'seen bell got rang stork saw jokeğŸ˜‚ğŸ˜‚ğŸ˜‚ animals phewwwğŸ˜‚ baby': 1, ...})"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dist "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
